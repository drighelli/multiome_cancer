---
title: "An introduction to the TENxMultiomeTools package 2"
author: "Dario Righelli"
date: "`r Sys.Date()`"
output: 
    BiocStyle::html_document:
        toc: false
    vignette: >
      %\VignetteIndexEntry{An introduction to the TENxMultiomeTools package}
      %\VignetteEncoding{UTF-8}
      %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(BiocStyle)
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
```

# Requirements

```{r, message=FALSE}
library(TENxMultiomeTools)
library(AllenInstituteBrainData)
library(Signac)
library(Seurat)
library(EnsDb.Mmusculus.v79)
library(scuttle)
library(scater)
```

# Introduction

The `TENxMultiomeTools` package is a work in progress project intended to 
facilitate the loading and handling of 10x Genomics multiome data in
`SingleCellExperiment` format.

This pipeline starts from the output generated by the 10x cellranger-ARC 
pipeline and sis designed for differential analysis of multiple samples in 
different conditions.
We defined it while working on a complex design of 12 different multiome samples
of mouse brain cortex in 4 different condition.

Because the data are not published yet, we are using one of the publicly 
available dataset from the official 10x Genomics website to illustrate the 
available functionalities of the package and challanges faced with this type of
data.

Additionally, because of lack of public datasets with different conditions, we
cannot illustrate the full pipeline, but we'll go through the implemented
functionalities and we'll illustrate possible examples on real data.

# Loading Data

To facilitate 10x Genomics Multiome data loading we can use the `read10xMultiome` 
function, which takes the following parameters as input:

+ `sample_path`: the path of the experiment
+ `type`: the type of data to load, sparse/hdf5
+ `data`: data type to load, filtered/raw
+ `compressed`: logical indicating if the data are stored in a compressed format
+ `col.names`: logical indicating if to add ID to the cols of the assays.
+ `addfrags`: logical indicating if the path to the fragments file has to be 
saved in the sce.  Note that this is needed when computing the metrics in the 
next step.
+ `reference`: character indicating the reference assay to use as main assay

This function loads the data in a `SingleCellExperiment` format, creating a `main`
assay and an `altExp` assay, which is another `SingleCellExperiment` object.
The `colData` of the main assay will always contain the information related to the
cells of the experiment, so it will not be replicated twice, but only stored in
the main one.
On the other hand the information related to the rows of the assays differ because
for the RNA a `rowData` `DataFrame` stores information about the genes, while for 
the ATAC data it will be in a `rowRanges` format. This format allows to store the
information about the peaks in a `GenomicRanges` format where the genomic
coordinates are in the form of Chromosome, Start and End while additional data 
are stored in the `mcols` `DataFrame.`

```{r, eval=TRUE}
path="multiome_website_mouse_old/outs/"
sce <- read10xMultiome(
    sample.path=path,
    type="sparse",
    data="filtered",
    compressed=TRUE,
    col.names=TRUE,
    addfrags=TRUE,
    reference="RNA")
sce
colData(sce)
rowData(sce)
altExp(sce)
rowRanges(altExp(sce))


scelist <- lapply(c("multiome_website_mouse_old", "multiome_website_mouse_old_rep2"),    
    read10xMultiome, 
        type="HDF5", addfrags=TRUE)

names(scelist) <- c("Brain_R1", "Brain_R2")

```

# Create Annotation

The 10x Multiome default output comes with an `annotation` file for the detected
genes, but this file could be very heavy to store in memory and to manipulate.
A way to avoid this is to create an annotation by aid of an EnsDb package, which
downloads the annotation data for an entire genome.

```{r, message=FALSE, warning=FALSE}
ensdb <- EnsDb.Mmusculus.v79
seqlevelsStyle(ensdb) <- "UCSC"
annotation <- GetGRangesFromEnsDb(ensdb = ensdb)
genome(annotation) <- "mm10"
```


# Quality Control

Once that we have the data loaded and an annotation object in GenomicRanges format,
we can start by computing some quality control metrics.

At the moment we defined three quality controls approaches, the Signac metrics, 
the `scuttle::isOutlier` and the doublets detection implemented in the 
`scDblFinder` package, but we'll focus on the Signac metrics for this tutorial.

## Signac Metrics

At the moment we implemented a wrapper for the Signac package (available on CRAN),
which allows to compute multiple metrics both on RNA and ATAC data.

The metrics computed by Signac are defined as follows: 

+ number of counts per each gene for the RNA and each feature for the ATAC
+ the number of features on the RNA
+ computing the ratio of fragments between 147 bp and 294 bp (mononucleosome) 
to fragments < 147 bp (nucleosome-free)
+ computing the TSS enrichment score as defined by *Encode*: 
    + normalized score on the number of reads around (2000bp up/down) the TSS 

```{r}

scelist <- lapply(scelist, computeSignacMetrics, annotation)
```


## Compute filters on the previous metrics

Once we have the `Signac` metrics computed, we can use them to filter-out 
low-quality cells.
To do so, we decided to compute the quantiles of the distribution of each 
metric.

We defined the low-quality cells as the ones that have at the same time all these
checks passed:
+ number of counts per genes and features lower than the lowest quantile 
(default 5%) and higher than the highest quantile (default 95%).
+ number of features on the RNA lower than the lowest quantile (default 5%) 
and higher than the highest quantile(default 95%).
+ nucleosome signal lower than 2
+ TSS enrichment lower that 1

We can choose this thresholds by hand with the `lowQuantThr`, `highQuantThr`, 
`nucleosomeThr` and `TSSThr`, parameters in the `computeFilterCellsMetrics` 
function.

Of course the default parameters can be chosen with an heuristic approach.

```{r}

scelist <- lapply(scelist, function(sce)
{
    computeFilterCellsMetrics(sce, metric="quantile",
    lowQuantThr="5%", highQuantThr="90%",
    nucleosomeThr=2, TSSThr=1)
})
```

## Quality Control Plots

We can take a look to the distributions and the labeled cells with the 
`plotFilteredCells` function, which shows violin plots for all the metrics 
computed and colors the cells based on the quality control passed/not passed 
label.

The arguments of this function allow to plot the filtered-in/out cells with the 
`inout` parameter. Of course we are mainly interested in the filtered-out cells
because we want to better understand if there is something important the we're
filtering out.

It is also possible to pass a custom column with a user-defined column name 
with `TRUE`/`FALSE` values indicating the kept/filtered cells, by aid of the
`filterCellsBy` and `customColName` parameters.

```{r}
plotFilteredCells(sce, name="test", inout="out")
```

## Doublets

Another Quality Control on the cells can be done by computing doublets scores.
We implemented a wrapper on the `scDblFinder` package, 
because it offers multiple methods for doublets detection.
In particular, the doublet score for each cell is based on the density of 
simulated doublets around it.

Even if the results provided by this package are still under verification,
we suggest to use it to better understand the quality of the cells in the 
experiment.

Actually, we implemented the method for the scRNAseq data, but further 
implementations will take into account methods for scATACseq data and further
investigations need to be done on how to apply these methods on both assays.

```{r}
scelist <- lapply(scelist, logNormCounts)
scelist <- lapply(scelist, computeDoublets, method="griffiths")
```

It is possible to visualize these results with a simple TSNE plot, but better
investigations can be done when cell types labels will be assigned to our cell 
and looking where the doublets fall in our dataset.

```{r}
sce <- runPCA(sce, ntop=length(rownames(sce)))
sce <- runTSNE(sce, dimred="PCA")
plotTSNE(sce, colour_by="dbl.scores") + theme_bw()
plotTSNE(sce, colour_by="dbl.calls") + theme_bw()
```

## Filtering Cells

Once we retain satisfied with the Quality Controls we can proceed by filtering
the cells and to normalize the data.

We highlight that the `in_signac` column is automatically computed in the 
`computeFilterCellsMetrics` and it is a logical `AND` across all the metrics 
described in the previous "Signac" steps.

```{r}
scelist <- lapply(scelist, function(sce) {
    sce <- sce[,sce$in_signac]
    sce <- runPCA(sce, ntop=length(rownames(sce)))
    sce <- runTSNE(sce, dimred="PCA")
    sce
})
# scelist <- lapply(scelist, logNormCounts)
# scelist <- lapply(scelist, function)
# # sce <- sce[,sce$in_signac]
# sce <- logNormCounts(sce)
# sce <- runPCA(sce, ntop=length(rownames(sce)))
# sce <- runTSNE(sce, dimred="PCA")
```


# Assign Cell Labels

To assign cell labels there are several methods available in literature, some of
which requires a reference dataset which helps to map the cell labels from the
reference to our dataset.

At the moment there are not so many reliable reference dataset easisly available,
in particular with validated cell types and, obviously, not for any kind of tissue
we could need.

## Cell Types Reference

For this tutorial, we are using a reference dataset from the Allen Institute, 
available from the `AllenInstituteBrainData` package [https://github.com/drighelli/AllenInstituteBrainData](https://github.com/drighelli/AllenInstituteBrainData) 
which allows to download an annotated dataset of ~1 Million mouse brain cells 
annotated at three different levels of taxonomy. 

This reference has three levels of annotation graularity:

+ the cluster level is the level where the cells have been clustered in
+ the subclass level is the level where the cells have been validated thank to cell-type
markers
+ the class level is the level where the cells have been grouped together because
of cell-types belonging to the same cell family.

After downloading the dataset, it could be useful to create pseudo-bulk counts
to speed up our computations.
Using a reference of 1 Million cells could take very long time during the process
of cell type annotation, and from our tests using the pseudo-bulk counts is a 
pretty good approximation in terms of the obtained results.

```{r, eval=FALSE}
allen <- AllenInstituteBrainData("Allen_Mouse_2020")
allen <- aggregateAcrossCells(allen, use.assay.type = "counts",id=DataFrame(label=allen$subclass_label))
allen <- logNormCounts(allen)
```

We need to map the annotation in the same gene format as our dataset to compute
the cell labels in the next step.

```{r}
allen <- readRDS("allen_pseudo.RDS")
rownames(allen) <- rowData(allen)$X
symbol_allen <- rownames(allen)
map <- mapIds(EnsDb.Mmusculus.v79, keys= symbol_allen, keytype = "SYMBOL", 
        column = "GENEID")
stopifnot(length(map) == nrow(allen))
rowData(allen)$symbol <- symbol_allen
rowData(allen)$ens <- map
allen <- allen[!is.na(rowData(allen)$ens),]
rownames(allen) <- rowData(allen)$ens
allen <- logNormCounts(allen)
```


## Assigning labels to the cells 

At this point we can simply assign the labels from the reference to our 
dataset. 
At the moment, we created a wrapper `assignLabels` around the `SingleR` package, 
but, as already mentioned, there is plenty of methods that can be used for this 
scope.

Indeed, further versions of this function will implement other methods, 
i.e. `Azimuth` from Rahul Satija lab.

```{r}
# allen <- logNormCounts(allen)
scelist <- lapply(scelist, function(sce){assignLabels(sce, allen, "subclass_label")})
# sce <- assignLabels(sce, allen, "subclass_label")
# colData(sce)
# head(sce$SingleR)
```

# Visualizing cell types

Once we have the cell types labeled for our experiment, we are interested in 
understanding their clustering and this can be easily done with the `plotTSNE`
function of the `scater` package.

```{r}
plotTSNE(sce, colour_by="SingleR")
```

# Differential Analysis

We selected two main approaches for doing differential analysis of these data,
by applying muscat (working on single cell data) and by using edgeR (working on
bulk data).

Because the second one produced better results on our datasets, we are going to 
illustrate the steps that can be performed to apply edgeR on single cell data
to obtain differentially expressed genes (RNA) and differential accessible 
regions (ATAC).

To apply bulk analysis methods on single cell data, these need to be transformed
in pseudo-bulk counts, and to do so there are multiple methods able to do that.

NB: We are not pointing to not use muscat (or other methods), but to always compare 
the results produced by multiple approaches to better investigate your data.

## Pseudobulk

A possible approach to obtain pseudo-bulk data from your single-cell is to 
use the `aggregateAcrossCells` method from the `scuttle` package
(as previously done for the reference dataset).

To apply this method we simply have to define a named vector of the cell types 
to use for the aggregation of the cells.
In our case, we saved this information in the `colData` of our `SingleCellExperiment`
under the `SingleR` column.

This approach is pretty straightforward when working with a scRNAseq because the
genes are well defined even when working with multiple experiments. 

In the end, we will have a new `SingleCellExperiment` with a reduced number of 
columns, which, in turn, will be of the same number of cell types defined in our
`SingleR` `colData` column.

```{r}
scelistps <- lapply(scelist, function(sce){
    aggregateAcrossCells(sce, use.assay.type="counts",
        id=DataFrame(label=sce$SingleR))
})
```


At this point it is possible to apply and visualize the data like bulk data.

```{r}
plotPCA(sce_pseudo, colour_by="SingleR")
```


The same operation can be made on a single ATAC experiment obtaining the same 
number of columns as for the RNA.

```{r}
sce_pseudo_atac <- aggregateAcrossCells(altExp(sce), use.assay.type="counts",
        id=DataFrame(label=sce$SingleR))
altExp(sce_pseudo) <- sce_pseudo_atac
```


```{r}

scelist <- lapply(scelist, function(sce){
    lapply(unique(sce$SingleR), function(ct){
        createBamCt(sce, cellType=ct, cellTypesCol="SingleR",
            bamdir=metadata(sce)$path, outdir="bioc23/bams_allct", ncores=10)   
    })
})

# 
# 
# bams <- list.files("bioc23/bams", pattern="*.bam$", recursive=TRUE, full.names=TRUE)
# lapply(bams, function(bam)
# {
#     cmd <- paste0("samtools sort -@ 10 ", bam," -o ", gsub(".bam$", "", bam), "_sorted.bam")
#     print(cmd)
#     system(cmd)
# })
# bamss <- list.files("bioc23/bams", pattern="*_sorted.bam$", recursive=TRUE, full.names=TRUE)
# lapply(bamss, function(bam)
# {
#     cmd <- paste0("samtools index -b ", bam, " -@ 10 ")
#     print(cmd)
#     system(cmd)
# })

```


```{r}
## DEScan2
## 
scelist1 <- lapply(scelist, function(sce) {
    buildATACScores(sce, cellType="Astro")
})
grl <- lapply(scelist1, function(sce) {rowRanges(altExp(sce))})
gr <- finalRegions(GRangesList(grl), 
            zThreshold=0, minCarriers=1, saveFlag=FALSE, 
            scorecolname="score", verbose=TRUE,#scoreBy="groups",
            BPPARAM=BiocParallel::MulticoreParam(workers=1)) 


### show histogram on number of carriers and peaks integrated ####

bams <- list.files("bioc23/bams", pattern="*sorted.bam$", recursive=TRUE, full.names=TRUE)
bams <- bams[grep(pattern="ATAC", x=bams)]


lapply(bams, function(b){
    system(paste0("mv ", b, " bioc23/bams", basename(b)))
})


lapply(bams, function(b){
    system(paste0("mv ", b, ".bai bioc23/bams", basename(b),".bai"))
})



bamdir <- "bioc23/"

grSE <- countFinalRegions(gr, readsFilePath=bamdir, 
                        fileType="bam", minCarriers=1)


```


But things become a little bit more complicated when having multiple ATAC
experiments, coming from different conditions,
it could be problematic to compute a pseudo-bulk counts, because of the 
differences across the peaks (each experiment has different number of peaks
and coordinates).

At the moment, to provide a solution to this issue, we are implementing 
(still needing some bug fixing and testing) a solution to this problem by 
adapting the `finalRegions` function present in the 
`DEScan2` package, which will return a new `SingleCellExperiment` object with 
the pseudo-count matrix computed on the multiple experiments.

Additionally, both previous operations on a single experiment can be made with 
our wrapper `computePseudoBulk` in a unique instruction that computes 
pseudo-bulk counts both for RNA and ATAC assays.

```{r, eval=FALSE}
sce_pseudo <- computePseudoBulk(sce, ctCol="SingleR")
```

At this point, it is easy to apply standard bulk pipelines to obtain 
differentially expressed genes and differentially accessible regions, 
per each cell type across different conditions.

Like applying normalization, PCA, gene-filtering and classical differential 
approaches like `edgeR` and `DESeq2`.

# Create and export tracks

In order to visualize tracks for a specific cell type in the *UCSC Genome Browser* 
we implemented a function which takes care to export our data in *BigWig* format.
To do so, the function needs some external software and the path to the original
bam files of the experiment.

In particular it uses the following tools:

+ `sinto`: a python software to create bam files per each cell type starting from 
a list of barcodes (the ones of the specified cell type)
+ `samtools`: useful to sort and index the new bam files
+ `deeptools` bamCoverage: to create bigwig files of the freshly created bam files

Once we have the *BigWig* files, we can easily create a new session in the 
*UCSC Genome Browser* and upload them to inspect them.

Further implementation of this function will try to avoid as much external 
tools as possible, possibly by aid of the `rtracklayer` package, and automatically
create a session with the desired tracks.

```{r, eval=FALSE}
createTracks(sce, cellTypesCol="SingleR", cellType="CR", bamdir=path, 
    outdir=path, ncores=10)
```

# Session Info

```{r}
sessionInfo()
```






